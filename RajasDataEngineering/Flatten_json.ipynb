{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83d1429e-02d4-46ce-86ec-961870b90169",
     "showTitle": false,
     "title": ""
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "https://medium.com/@thomaspt748/how-to-flatten-json-files-dynamically-using-apache-pyspark-c6b1b5fd4777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "547daa87-f3ad-4e66-aa38-1439429b5148",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from typing import Final, Dict, Tuple\n",
    "\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql import DataFrame as SDF\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f22f74d-dfa4-4942-a4ff-5e48b1a2b739",
     "showTitle": false,
     "title": ""
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def rename_dataframe_cols(df: SDF, col_names: Dict[str, str]) -> SDF:\n",
    "    \"\"\"\n",
    "    Rename all columns in dataframe\n",
    "    \"\"\"\n",
    "    return df.select(*[col(col_name).alias(col_names.get(col_name, col_name)) for col_name in df.columns])\n",
    "\n",
    "def update_column_names(df: SDF, index: int) -> SDF:\n",
    "    df_temp = df\n",
    "    all_cols = df_temp.columns\n",
    "    new_cols = dict((column, f\"{column}*{index}\") for column in all_cols)\n",
    "    df_temp = df_temp.transform(lambda df_x: rename_dataframe_cols(df_x, new_cols))\n",
    "\n",
    "    return df_temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11fac43a-2ef2-4cac-b35b-69b6060a585c",
     "showTitle": false,
     "title": ""
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def flatten_json(df_arg: SDF, index: int = 1) -> SDF:\n",
    "    \"\"\"\n",
    "    Flatten Json in a spark dataframe using recursion\n",
    "    \"\"\"\n",
    "\t# Update all column names with index 1\n",
    "    df = update_column_names(df_arg, index) if index == 1 else df_arg\n",
    "\n",
    "\t# Get all field names fron the dataframe\n",
    "    fields = df.schema.fields\n",
    "\n",
    "\t# For all columns in the dataframe\n",
    "    for field in fields:\n",
    "        data_type = str(field.dataType)\n",
    "        column_name = field.name\n",
    "\n",
    "        first_10_chars = data_type[0:10]\n",
    "\t\n",
    "        # If it is an Array column\n",
    "        if first_10_chars == 'ArrayType(':\n",
    "            # Explode Array column\n",
    "            df_temp = df.withColumn(column_name, explode_outer(col(column_name)))\n",
    "            return flatten_json(df_temp, index + 1)\n",
    "\n",
    "        # If it is a json object\n",
    "        elif first_10_chars == 'StructType':\n",
    "            current_col = column_name\n",
    "            \n",
    "            append_str = current_col\n",
    "\n",
    "            # Get data type of current column\n",
    "            data_type_str = str(df.schema[current_col].dataType)\n",
    "\n",
    "            # Change the column name if the current column name exists in the data type string\n",
    "            df_temp = df.withColumnRenamed(column_name, column_name + \"#1\") \\\n",
    "                if column_name in data_type_str else df\n",
    "            current_col = current_col + \"#1\" if column_name in data_type_str else current_col\n",
    "\n",
    "            # Expand struct column values\n",
    "            df_before_expanding = df_temp.select(f\"{current_col}.*\")\n",
    "            newly_gen_cols = df_before_expanding.columns\n",
    "\n",
    "            # Find next level value for the column\n",
    "            begin_index = append_str.rfind('*')\n",
    "            end_index = len(append_str)\n",
    "            level = append_str[begin_index + 1: end_index]\n",
    "            next_level = int(level) + 1\n",
    "\n",
    "            # Update column names with new level\n",
    "            custom_cols = dict((field, f\"{append_str}->{field}*{next_level}\") for field in newly_gen_cols)\n",
    "            df_temp2 = df_temp.select(\"*\", f\"{current_col}.*\").drop(current_col)\n",
    "            df_temp3 = df_temp2.transform(lambda df_x: rename_dataframe_cols(df_x, custom_cols))\n",
    "            return flatten_json(df_temp3, index + 1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66d83c7e-f277-4988-a478-491a4f77157d",
     "showTitle": false,
     "title": ""
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"FlatJson\") \\\n",
    "        .master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4eb08b80-c5f9-4ad7-8b26-5d3f9e9f2b01",
     "showTitle": false,
     "title": ""
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "sample_json1 = \"\"\"\n",
    "[\n",
    "\t{\n",
    "\t\t\"id\": \"0001\",\n",
    "\t\t\"type\": \"donut\",\n",
    "\t\t\"name\": \"Cake\",\n",
    "\t\t\"___tr\": true,\n",
    "\t\t\"ppu\": 0.55,\n",
    "\t\t\"batters\":\n",
    "\t\t\t{\n",
    "\t\t\t\t\"batter\":\n",
    "\t\t\t\t\t[\n",
    "\t\t\t\t\t\t{ \"id\": \"1001\", \"type\": \"Regular\" },\n",
    "\t\t\t\t\t\t{ \"id\": \"1002\", \"type\": \"Chocolate\" },\n",
    "\t\t\t\t\t\t{ \"id\": \"1003\", \"type\": \"Blueberry\" },\n",
    "\t\t\t\t\t\t{ \"id\": \"1004\", \"type\": \"Devil's Food\" }\n",
    "\t\t\t\t\t]\n",
    "\t\t\t},\n",
    "\t\t\"topping\":\n",
    "\t\t\t[\n",
    "\t\t\t\t{ \"id\": \"5001\", \"type\": \"None\" },\n",
    "\t\t\t\t{ \"id\": \"5002\", \"type\": \"Glazed\" },\n",
    "\t\t\t\t{ \"id\": \"5005\", \"type\": \"Sugar\" },\n",
    "\t\t\t\t{ \"id\": \"5007\", \"type\": \"Powdered Sugar\" },\n",
    "\t\t\t\t{ \"id\": \"5006\", \"type\": \"Chocolate with Sprinkles\" },\n",
    "\t\t\t\t{ \"id\": \"5003\", \"type\": \"Chocolate\" },\n",
    "\t\t\t\t{ \"id\": \"5004\", \"type\": \"Maple\" }\n",
    "\t\t\t]\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": \"0002\",\n",
    "\t\t\"type\": \"donut\",\n",
    "\t\t\"name\": \"Raised\",\n",
    "\t\t\"ppu\": 0.55,\n",
    "\t\t\"batters\":\n",
    "\t\t\t{\n",
    "\t\t\t\t\"batter\":\n",
    "\t\t\t\t\t[\n",
    "\t\t\t\t\t\t{ \"id\": \"1001\", \"type\": \"Regular\" }\n",
    "\t\t\t\t\t]\n",
    "\t\t\t},\n",
    "\t\t\"topping\":\n",
    "\t\t\t[\n",
    "\t\t\t\t{ \"id\": \"5001\", \"type\": \"None\" },\n",
    "\t\t\t\t{ \"id\": \"5002\", \"type\": \"Glazed\" },\n",
    "\t\t\t\t{ \"id\": \"5005\", \"type\": \"Sugar\" },\n",
    "\t\t\t\t{ \"id\": \"5003\", \"type\": \"Chocolate\" },\n",
    "\t\t\t\t{ \"id\": \"5004\", \"type\": \"Maple\" }\n",
    "\t\t\t]\n",
    "\t},\n",
    "\t{\n",
    "\t\t\"id\": \"0003\",\n",
    "\t\t\"type\": \"donut\",\n",
    "\t\t\"name\": \"Old Fashioned\",\n",
    "\t\t\"ppu\": 0.55,\n",
    "\t\t\"batters\":\n",
    "\t\t\t{\n",
    "\t\t\t\t\"batter\":\n",
    "\t\t\t\t\t[\n",
    "\t\t\t\t\t\t{ \"id\": \"1001\", \"type\": \"Regular\" },\n",
    "\t\t\t\t\t\t{ \"id\": \"1002\", \"type\": \"Chocolate\" }\n",
    "\t\t\t\t\t]\n",
    "\t\t\t},\n",
    "\t\t\"topping\":\n",
    "\t\t\t[\n",
    "\t\t\t\t{ \"id\": \"5001\", \"type\": \"None\" },\n",
    "\t\t\t\t{ \"id\": \"5002\", \"type\": \"Glazed\" },\n",
    "\t\t\t\t{ \"id\": \"5003\", \"type\": \"Chocolate\" },\n",
    "\t\t\t\t{ \"id\": \"5004\", \"type\": \"Maple\" }\n",
    "\t\t\t]\n",
    "\t}\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "sample_json = \"\"\"\n",
    "\n",
    "{\n",
    "    \"customer\": {\n",
    "      \"id\": 123,\n",
    "      \"name\": \"John Doe\",\n",
    "      \"number\": [1, 2, 3, 4, 5],\n",
    "      \"address\": {\n",
    "        \"city\": \"New York\",\n",
    "        \"country\": \"USA\"\n",
    "      }\n",
    "    },\n",
    "    \"orders\": [\n",
    "      {\"id\": 101, \"amount\": 50},\n",
    "      {\"id\": 102, \"amount\": 100}\n",
    "    ]\n",
    "  }\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a3e6464-6035-42ce-898b-c8847e900f23",
     "showTitle": false,
     "title": ""
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "tsRDD = sc.parallelize([sample_json1])\n",
    "\n",
    "df2 = spark.read.option(\"multiline\", \"true\").json(tsRDD)\n",
    "\n",
    "# df2.show(10, False)\n",
    "df2.display()\n",
    "df3 = flatten_json(df2)\n",
    "\n",
    "df3.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c1dd5ce-71c0-4fa9-8f54-12d28268b0bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install pysparketl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6608f92d-37a6-4412-8a27-62a94bfde469",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = \"\"\" \n",
    "  {\n",
    "    \"id\": 75200,\n",
    "    \"drug\": {\n",
    "      \"current_status\": \"MARKETED\",\n",
    "      \"id\": 40,\n",
    "      \"drug_code\": 10044,\n",
    "      \"updated_date\": \"2021-02-08T05:00:09-05:00\",\n",
    "      \"company\": {\n",
    "        \"id\": 6,\n",
    "        \"created_date\": \"2017-03-09T13:22:33-05:00\",\n",
    "        \"updated_date\": \"2017-03-09T13:22:33-05:00\",\n",
    "        \"company_code\": 3699,\n",
    "        \"mfr_code\": \"BAX08\",\n",
    "        \"name\": \"BAXTER CORPORATION\",\n",
    "        \"company_type\": \"DIN OWNER\",\n",
    "        \"address_mailing_flag\": true,\n",
    "        \"address_billing_flag\": true,\n",
    "        \"address_notification_flag\": true,\n",
    "        \"address_other\": false,\n",
    "        \"address_report_display\": true,\n",
    "        \"suite_number\": \"\",\n",
    "        \"street_name\": \"7125 MISSISSAUGA ROAD\",\n",
    "        \"province\": \"ONTARIO\",\n",
    "        \"country\": \"CANADA\",\n",
    "        \"city\": \"MISSISSAUGA\",\n",
    "        \"postal_code\": \"L5N 0C2\",\n",
    "        \"post_office_box\": \"\"\n",
    "      },\n",
    "      \"drug_ingredients\": [\n",
    "        {\n",
    "          \"id\": 6959346,\n",
    "          \"ingredient\": {\n",
    "            \"id\": 44,\n",
    "            \"ingredient_code\": 53,\n",
    "            \"en_name\": \"POTASSIUM CHLORIDE\",\n",
    "            \"fr_name\": \"Chlorure de potassium\"\n",
    "          },\n",
    "          \"ingredient_supplied_ind\": \"I\",\n",
    "          \"strength\": \"150\",\n",
    "          \"strength_unit\": \"MG\",\n",
    "          \"strength_type\": \"\",\n",
    "          \"dosage_value\": \"100\",\n",
    "          \"dosage_unit\": \"ML\",\n",
    "          \"base\": false\n",
    "        },\n",
    "        {\n",
    "          \"id\": 6959345,\n",
    "          \"ingredient\": {\n",
    "            \"id\": 16,\n",
    "            \"ingredient_code\": 55,\n",
    "            \"en_name\": \"SODIUM CHLORIDE\",\n",
    "            \"fr_name\": \"Chlorure de sodium\"\n",
    "          },\n",
    "          \"ingredient_supplied_ind\": \"I\",\n",
    "          \"strength\": \"450\",\n",
    "          \"strength_unit\": \"MG\",\n",
    "          \"strength_type\": \"\",\n",
    "          \"dosage_value\": \"100\",\n",
    "          \"dosage_unit\": \"ML\",\n",
    "          \"base\": false\n",
    "        },\n",
    "        {\n",
    "          \"id\": 6959344,\n",
    "          \"ingredient\": {\n",
    "            \"id\": 10,\n",
    "            \"ingredient_code\": 42,\n",
    "            \"en_name\": \"DEXTROSE\",\n",
    "            \"fr_name\": \"Dextrose\"\n",
    "          },\n",
    "          \"ingredient_supplied_ind\": \"I\",\n",
    "          \"strength\": \"5\",\n",
    "          \"strength_unit\": \"G\",\n",
    "          \"strength_type\": \"\",\n",
    "          \"dosage_value\": \"100\",\n",
    "          \"dosage_unit\": \"ML\",\n",
    "          \"base\": false\n",
    "        }\n",
    "      ],\n",
    "      \"din\": \"00437999\",\n",
    "      \"brand_name\": \"(20MMOL/L) POTASSIUM CHLORIDE IN 5% DEXTROSE AND 0.45% SODIUM CHLORIDE INJECTION USP\",\n",
    "      \"brand_name_fr\": \"\",\n",
    "      \"descriptor\": \"\",\n",
    "      \"pediatric_flag\": false,\n",
    "      \"accession_number\": \"69690\",\n",
    "      \"number_of_ais\": \"3\",\n",
    "      \"ai_group_no\": \"0300097005\"\n",
    "    }\n",
    "  }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab7f595e-2655-4c3c-9993-a56683602a60",
     "showTitle": false,
     "title": ""
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from pysparketl.dataframes import flattenDF\n",
    "sc = spark.sparkContext\n",
    "# tsRDD = sc.parallelize([sample_json1])\n",
    "tsRDD = sc.parallelize([data])\n",
    "# Read your input dataframe that contains Json data\n",
    "rawJsonDF = spark.read.json(tsRDD)\n",
    "# Pass your nested json dataframe as input to the flattenDF function\n",
    "flattenedDF = flattenDF(rawJsonDF)\n",
    "\n",
    "display(flattenedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94af5208-7c67-4360-883e-4ff4dc7888f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Flatten_json",
   "widgets": {}
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "notebook_environment": {},
  "save_output": true,
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {},
    "enableDebugMode": false
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "trident": {
   "lakehouse": {}
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
