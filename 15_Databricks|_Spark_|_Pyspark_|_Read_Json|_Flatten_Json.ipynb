{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1rOlnpxy_p3aDFuHKpjRlBI7h9M-NwkqV",
      "authorship_tag": "ABX9TyOBvTWU1EBlrYdTk0vXv7Gw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loicbi/Databricks/blob/develop/15_Databricks%7C_Spark_%7C_Pyspark_%7C_Read_Json%7C_Flatten_Json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5poKsdENgL1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark"
      ],
      "metadata": {
        "id": "PAHeaUwSIS1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3N_gZyPFhMw"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "from pyspark.sql.functions import  * # to_date, col, split, char_length, lit, trim\n",
        "# findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "# spark = SparkSession.builder.appName(\"app_name\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
        "\n",
        "\n",
        "df = spark.read.option('multiline', 'true').json(\"/content/drive/MyDrive/DATA_ENGINEER/DATABRICKS/AAAA_________IAM___CODING_____Colab Notebooks/Learning/datasset/AFCON/json_files/US_category_id.json\")\n",
        "df.printSchema()\n",
        "df.show(10)\n"
      ],
      "metadata": {
        "id": "2YNmbGsDFon9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Flatten array of structs and structs\n",
        "def flatten(df):\n",
        "  #  compute Complex Fields (Lists and Structs) in Schema\n",
        "   complex_fields = dict([(field.name, field.dataType)\n",
        "                             for field in df.schema.fields\n",
        "                             if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])\n",
        "   while len(complex_fields)!=0:\n",
        "      col_name=list(complex_fields.keys())[0]\n",
        "      print (\"Processing :\"+col_name+\" Type : \"+str(type(complex_fields[col_name])))\n",
        "\n",
        "      # if StructType then convert all sub element to columns.\n",
        "      # i.e. flatten structs\n",
        "      if (type(complex_fields[col_name]) == StructType):\n",
        "         expanded = [col(col_name+'.'+k).alias(col_name+'_'+k) for k in [ n.name for n in  complex_fields[col_name]]]\n",
        "         df=df.select(\"*\", *expanded).drop(col_name)\n",
        "\n",
        "      # if ArrayType then add the Array Elements as Rows using the explode function\n",
        "      # i.e. explode Arrays\n",
        "      elif (type(complex_fields[col_name]) == ArrayType):\n",
        "         df=df.withColumn(col_name,explode_outer(col_name))\n",
        "\n",
        "      # recompute remaining Complex Fields in Schema\n",
        "      complex_fields = dict([(field.name, field.dataType)\n",
        "                             for field in df.schema.fields\n",
        "                             if type(field.dataType) == ArrayType or  type(field.dataType) == StructType])\n",
        "   return df"
      ],
      "metadata": {
        "id": "AQhewVetmaG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_flatten = flatten(df)"
      ],
      "metadata": {
        "id": "pYv1Tt87mpFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_flatten.show()"
      ],
      "metadata": {
        "id": "Qu741ttJqSOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "data = r'''\n",
        "{\n",
        " \"kind\": \"youtube#videoCategoryListResponse\",\n",
        " \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/S730Ilt-Fi-emsQJvJAAShlR6hM\\\"\",\n",
        " \"items\": [\n",
        "  {\n",
        "   \"kind\": \"youtube#videoCategory\",\n",
        "   \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/Xy1mB4_yLrHy_BmKmPBggty2mZQ\\\"\",\n",
        "   \"id\": \"1\",\n",
        "   \"snippet\": {\n",
        "    \"channelId\": \"UCBR8-60-B28hp2BmDPdntcQ\",\n",
        "    \"title\": \"Film & Animation\",\n",
        "    \"assignable\": true\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"kind\": \"youtube#videoCategory\",\n",
        "   \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/UZ1oLIIz2dxIhO45ZTFR3a3NyTA\\\"\",\n",
        "   \"id\": \"2\",\n",
        "   \"snippet\": {\n",
        "    \"channelId\": \"UCBR8-60-B28hp2BmDPdntcQ\",\n",
        "    \"title\": \"Autos & Vehicles\",\n",
        "    \"assignable\": true\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"kind\": \"youtube#videoCategory\",\n",
        "   \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/nqRIq97-xe5XRZTxbknKFVe5Lmg\\\"\",\n",
        "   \"id\": \"10\",\n",
        "   \"snippet\": {\n",
        "    \"channelId\": \"UCBR8-60-B28hp2BmDPdntcQ\",\n",
        "    \"title\": \"Music\",\n",
        "    \"assignable\": true\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"kind\": \"youtube#videoCategory\",\n",
        "   \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/HwXKamM1Q20q9BN-oBJavSGkfDI\\\"\",\n",
        "   \"id\": \"15\",\n",
        "   \"snippet\": {\n",
        "    \"channelId\": \"UCBR8-60-B28hp2BmDPdntcQ\",\n",
        "    \"title\": \"Pets & Animals\",\n",
        "    \"assignable\": true\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"kind\": \"youtube#videoCategory\",\n",
        "   \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/9GQMSRjrZdHeb1OEM1XVQ9zbGec\\\"\",\n",
        "   \"id\": \"17\",\n",
        "   \"snippet\": {\n",
        "    \"channelId\": \"UCBR8-60-B28hp2BmDPdntcQ\",\n",
        "    \"title\": \"Sports\",\n",
        "    \"assignable\": true\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"kind\": \"youtube#videoCategory\",\n",
        "   \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/FJwVpGCVZ1yiJrqZbpqe68Sy_OE\\\"\",\n",
        "   \"id\": \"18\",\n",
        "   \"snippet\": {\n",
        "    \"channelId\": \"UCBR8-60-B28hp2BmDPdntcQ\",\n",
        "    \"title\": \"Short Movies\",\n",
        "    \"assignable\": false\n",
        "   }\n",
        "  },\n",
        "  {\n",
        "   \"kind\": \"youtube#videoCategory\",\n",
        "   \"etag\": \"\\\"m2yskBQFythfE4irbTIeOgYYfBU/M-3iD9dwK7YJCafRf_DkLN8CouA\\\"\",\n",
        "   \"id\": \"19\",\n",
        "   \"snippet\": {\n",
        "    \"channelId\": \"UCBR8-60-B28hp2BmDPdntcQ\",\n",
        "    \"title\": \"Travel & Events\",\n",
        "    \"assignable\": true\n",
        "   }\n",
        "  }\n",
        " ]\n",
        "} '''\n",
        "data = json.loads(data)\n",
        "\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dUg6JAEqUOt",
        "outputId": "c1e2cb09-f33e-43cb-80f2-661bb53d153b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kind': 'youtube#videoCategoryListResponse',\n",
              " 'etag': '\"m2yskBQFythfE4irbTIeOgYYfBU/S730Ilt-Fi-emsQJvJAAShlR6hM\"',\n",
              " 'items': [{'kind': 'youtube#videoCategory',\n",
              "   'etag': '\"m2yskBQFythfE4irbTIeOgYYfBU/Xy1mB4_yLrHy_BmKmPBggty2mZQ\"',\n",
              "   'id': '1',\n",
              "   'snippet': {'channelId': 'UCBR8-60-B28hp2BmDPdntcQ',\n",
              "    'title': 'Film & Animation',\n",
              "    'assignable': True}},\n",
              "  {'kind': 'youtube#videoCategory',\n",
              "   'etag': '\"m2yskBQFythfE4irbTIeOgYYfBU/UZ1oLIIz2dxIhO45ZTFR3a3NyTA\"',\n",
              "   'id': '2',\n",
              "   'snippet': {'channelId': 'UCBR8-60-B28hp2BmDPdntcQ',\n",
              "    'title': 'Autos & Vehicles',\n",
              "    'assignable': True}},\n",
              "  {'kind': 'youtube#videoCategory',\n",
              "   'etag': '\"m2yskBQFythfE4irbTIeOgYYfBU/nqRIq97-xe5XRZTxbknKFVe5Lmg\"',\n",
              "   'id': '10',\n",
              "   'snippet': {'channelId': 'UCBR8-60-B28hp2BmDPdntcQ',\n",
              "    'title': 'Music',\n",
              "    'assignable': True}},\n",
              "  {'kind': 'youtube#videoCategory',\n",
              "   'etag': '\"m2yskBQFythfE4irbTIeOgYYfBU/HwXKamM1Q20q9BN-oBJavSGkfDI\"',\n",
              "   'id': '15',\n",
              "   'snippet': {'channelId': 'UCBR8-60-B28hp2BmDPdntcQ',\n",
              "    'title': 'Pets & Animals',\n",
              "    'assignable': True}},\n",
              "  {'kind': 'youtube#videoCategory',\n",
              "   'etag': '\"m2yskBQFythfE4irbTIeOgYYfBU/9GQMSRjrZdHeb1OEM1XVQ9zbGec\"',\n",
              "   'id': '17',\n",
              "   'snippet': {'channelId': 'UCBR8-60-B28hp2BmDPdntcQ',\n",
              "    'title': 'Sports',\n",
              "    'assignable': True}},\n",
              "  {'kind': 'youtube#videoCategory',\n",
              "   'etag': '\"m2yskBQFythfE4irbTIeOgYYfBU/FJwVpGCVZ1yiJrqZbpqe68Sy_OE\"',\n",
              "   'id': '18',\n",
              "   'snippet': {'channelId': 'UCBR8-60-B28hp2BmDPdntcQ',\n",
              "    'title': 'Short Movies',\n",
              "    'assignable': False}},\n",
              "  {'kind': 'youtube#videoCategory',\n",
              "   'etag': '\"m2yskBQFythfE4irbTIeOgYYfBU/M-3iD9dwK7YJCafRf_DkLN8CouA\"',\n",
              "   'id': '19',\n",
              "   'snippet': {'channelId': 'UCBR8-60-B28hp2BmDPdntcQ',\n",
              "    'title': 'Travel & Events',\n",
              "    'assignable': True}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PySpark â€” Flatten JSON/Struct Data Frame dynamically\n",
        "\n",
        "[JSON/Struct Data Frame dynamically](https://subhamkharwal.medium.com/pyspark-flatten-json-struct-data-frame-dynamically-c2e5d8937dcc)"
      ],
      "metadata": {
        "id": "q2EBMvkP6Vsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create an Example Data Frame to hold JSON data\n",
        "# Example Data Frame with column having JSON data\n",
        "_data = [\n",
        "    ['EMP001', '{\"dept\" : \"account\", \"fname\": \"Ramesh\", \"lname\": \"Singh\", \"skills\": [\"excel\", \"tally\", \"word\"]}'],\n",
        "    ['EMP002', '{\"dept\" : \"sales\", \"fname\": \"Siv\", \"lname\": \"Kumar\", \"skills\": [\"biking\", \"sales\"]}'],\n",
        "    ['EMP003', '{\"dept\" : \"hr\", \"fname\": \"MS Raghvan\", \"skills\": [\"communication\", \"soft-skills\"], \"hobbies\" : {\"cycling\": \"expert\", \"computers\":\"basic\"}}'],\n",
        "    ['EMP003', '{\"dept\" : \"hr\", \"fname\": \"MS Raghvan\", \"skills\": [\"communication\", \"soft-skills\"], \"hobbies\" : {\"cycling\": \"expert\", \"computers\":\"basic\"}}']\n",
        "]\n",
        "\n",
        "# Columns for the data\n",
        "_cols = ['emp_no', 'raw_data']\n",
        "\n",
        "# Lets create the raw Data Frame\n",
        "df_raw = spark.createDataFrame(data = _data, schema = _cols)\n",
        "\n",
        "# Determine the schema of the JSON payload from the column\n",
        "json_schema_df = spark.read.json(df_raw.rdd.map(lambda row: row.raw_data))\n",
        "json_schema = json_schema_df.schema\n",
        "\n",
        "# Apply the schema to payload to read the data\n",
        "from pyspark.sql.functions import from_json\n",
        "df_details = df_raw.withColumn(\"emp_details\", from_json(df_raw[\"raw_data\"], json_schema)).drop(\"raw_data\")\n",
        "df_details.show(10, False)\n",
        "\n",
        "df_details.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQjICq4g4_G_",
        "outputId": "46dfeedd-5d30-40b3-d3f2-7321d2b9a90b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------------------------------------------------------------------+\n",
            "|emp_no|emp_details                                                          |\n",
            "+------+---------------------------------------------------------------------+\n",
            "|EMP001|{account, Ramesh, NULL, Singh, [excel, tally, word]}                 |\n",
            "|EMP002|{sales, Siv, NULL, Kumar, [biking, sales]}                           |\n",
            "|EMP003|{hr, MS Raghvan, {basic, expert}, NULL, [communication, soft-skills]}|\n",
            "|EMP003|{hr, MS Raghvan, {basic, expert}, NULL, [communication, soft-skills]}|\n",
            "+------+---------------------------------------------------------------------+\n",
            "\n",
            "root\n",
            " |-- emp_no: string (nullable = true)\n",
            " |-- emp_details: struct (nullable = true)\n",
            " |    |-- dept: string (nullable = true)\n",
            " |    |-- fname: string (nullable = true)\n",
            " |    |-- hobbies: struct (nullable = true)\n",
            " |    |    |-- computers: string (nullable = true)\n",
            " |    |    |-- cycling: string (nullable = true)\n",
            " |    |-- lname: string (nullable = true)\n",
            " |    |-- skills: array (nullable = true)\n",
            " |    |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Python function to flatten the data dynamically\n",
        "from pyspark.sql import DataFrame\n",
        "# Create outer method to return the flattened Data Frame\n",
        "def flatten_json_df(_df: DataFrame) -> DataFrame:\n",
        "    # List to hold the dynamically generated column names\n",
        "    flattened_col_list = []\n",
        "\n",
        "    # Inner method to iterate over Data Frame to generate the column list\n",
        "    def get_flattened_cols(df: DataFrame, struct_col: str = None) -> None:\n",
        "        for col in df.columns:\n",
        "            if df.schema[col].dataType.typeName() != 'struct':\n",
        "                if struct_col is None:\n",
        "                    flattened_col_list.append(f\"{col} as {col.replace('.','_')}\")\n",
        "                else:\n",
        "                    t = struct_col + \".\" + col\n",
        "                    flattened_col_list.append(f\"{t} as {t.replace('.','_')}\")\n",
        "            else:\n",
        "                chained_col = struct_col +\".\"+ col if struct_col is not None else col\n",
        "                get_flattened_cols(df.select(col+\".*\"), chained_col)\n",
        "\n",
        "    # Call the inner Method\n",
        "    get_flattened_cols(_df)\n",
        "\n",
        "    # Return the flattened Data Frame\n",
        "    return _df.selectExpr(flattened_col_list)# Generate the flattened DF\n",
        "flattened_df = flatten_json_df(df_details)\n",
        "flattened_df.show(10)\n",
        "# Print Schema\n",
        "flattened_df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X0IutCLHTKG",
        "outputId": "29c6d522-5d65-41c8-9198-24649dea0007"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------------+-----------------+-----------------------------+---------------------------+-----------------+--------------------+\n",
            "|emp_no|emp_details_dept|emp_details_fname|emp_details_hobbies_computers|emp_details_hobbies_cycling|emp_details_lname|  emp_details_skills|\n",
            "+------+----------------+-----------------+-----------------------------+---------------------------+-----------------+--------------------+\n",
            "|EMP001|         account|           Ramesh|                         NULL|                       NULL|            Singh|[excel, tally, word]|\n",
            "|EMP002|           sales|              Siv|                         NULL|                       NULL|            Kumar|     [biking, sales]|\n",
            "|EMP003|              hr|       MS Raghvan|                        basic|                     expert|             NULL|[communication, s...|\n",
            "+------+----------------+-----------------+-----------------------------+---------------------------+-----------------+--------------------+\n",
            "\n",
            "root\n",
            " |-- emp_no: string (nullable = true)\n",
            " |-- emp_details_dept: string (nullable = true)\n",
            " |-- emp_details_fname: string (nullable = true)\n",
            " |-- emp_details_hobbies_computers: string (nullable = true)\n",
            " |-- emp_details_hobbies_cycling: string (nullable = true)\n",
            " |-- emp_details_lname: string (nullable = true)\n",
            " |-- emp_details_skills: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flattening deep nested JSON using python and Databricks\n",
        "[link text](https://sanajitghosh.medium.com/flattening-deep-nested-json-using-python-and-databricks-110d097efa69)"
      ],
      "metadata": {
        "id": "Vekd5Y6-Ns_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import explode\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql.functions import arrays_zip\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "#load json object\n",
        "df = spark.read.option(\"multiline\",\"true\").json('/content/drive/MyDrive/DATA_ENGINEER/DATABRICKS/AAAA_________IAM___CODING_____Colab Notebooks/Learning/datasset/AFCON/json_files/data.json')\n",
        "\n",
        "def child_struct(nested_df):\n",
        "    # Creating python list to store dataframe metadata\n",
        "    list_schema = [((), nested_df)]\n",
        "    # Creating empty python list for final flattern columns\n",
        "    flat_columns = []\n",
        "\n",
        "    while len(list_schema) > 0:\n",
        "      # Removing latest or recently added item (dataframe schema) and returning into df variable\n",
        "          parents, df = list_schema.pop()\n",
        "          flat_cols = [  col(\".\".join(parents + (c[0],))).alias(\"_\".join(parents + (c[0],))) for c in df.dtypes if c[1][:6] != \"struct\"   ]\n",
        "\n",
        "          struct_cols = [  c[0]   for c in df.dtypes if c[1][:6] == \"struct\"   ]\n",
        "\n",
        "          flat_columns.extend(flat_cols)\n",
        "          #Reading  nested columns and appending into stack list\n",
        "          for i in struct_cols:\n",
        "                projected_df = df.select(i + \".*\")\n",
        "                list_schema.append((parents + (i,), projected_df))\n",
        "    return nested_df.select(flat_columns)\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "def master_array(df):\n",
        "    array_cols = [c[0] for c in df.dtypes if c[1][:5]==\"array\"]\n",
        "    while len(array_cols)>0:\n",
        "        for c in array_cols:\n",
        "            df = df.withColumn(c,explode_outer(c))\n",
        "        df = child_struct(df)\n",
        "        array_cols = [c[0] for c in df.dtypes if c[1][:5]==\"array\"]\n",
        "    return df\n",
        "\n",
        "df_output = master_array(df)\n",
        "display(df_output)\n",
        "df_output.show(50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lQqEIDYiNscF",
        "outputId": "c6307ed2-5019-4e3c-f066-cbaa99338e31"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "DataFrame[id: string, name: string, ppu: double, type: string, topping_id: string, topping_type: string, items_etag: string, items_id: string, items_kind: string, items_snippet_assignable: boolean, items_snippet_channelId: string, items_snippet_title: string, batters_batter_id: string, batters_batter_type: string]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------------+----+-----+----------+--------------------+--------------------+--------+--------------------+------------------------+-----------------------+-------------------+-----------------+-------------------+\n",
            "|  id|         name| ppu| type|topping_id|        topping_type|          items_etag|items_id|          items_kind|items_snippet_assignable|items_snippet_channelId|items_snippet_title|batters_batter_id|batters_batter_type|\n",
            "+----+-------------+----+-----+----------+--------------------+--------------------+--------+--------------------+------------------------+-----------------------+-------------------+-----------------+-------------------+\n",
            "|0001|         Cake|0.55|donut|      5001|                None|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0001|         Cake|0.55|donut|      5001|                None|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1002|          Chocolate|\n",
            "|0001|         Cake|0.55|donut|      5001|                None|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1003|          Blueberry|\n",
            "|0001|         Cake|0.55|donut|      5001|                None|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1004|       Devil's Food|\n",
            "|0001|         Cake|0.55|donut|      5002|              Glazed|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0001|         Cake|0.55|donut|      5002|              Glazed|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1002|          Chocolate|\n",
            "|0001|         Cake|0.55|donut|      5002|              Glazed|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1003|          Blueberry|\n",
            "|0001|         Cake|0.55|donut|      5002|              Glazed|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1004|       Devil's Food|\n",
            "|0001|         Cake|0.55|donut|      5005|               Sugar|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0001|         Cake|0.55|donut|      5005|               Sugar|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1002|          Chocolate|\n",
            "|0001|         Cake|0.55|donut|      5005|               Sugar|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1003|          Blueberry|\n",
            "|0001|         Cake|0.55|donut|      5005|               Sugar|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1004|       Devil's Food|\n",
            "|0001|         Cake|0.55|donut|      5007|      Powdered Sugar|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0001|         Cake|0.55|donut|      5007|      Powdered Sugar|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1002|          Chocolate|\n",
            "|0001|         Cake|0.55|donut|      5007|      Powdered Sugar|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1003|          Blueberry|\n",
            "|0001|         Cake|0.55|donut|      5007|      Powdered Sugar|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1004|       Devil's Food|\n",
            "|0001|         Cake|0.55|donut|      5006|Chocolate with Sp...|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0001|         Cake|0.55|donut|      5006|Chocolate with Sp...|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1002|          Chocolate|\n",
            "|0001|         Cake|0.55|donut|      5006|Chocolate with Sp...|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1003|          Blueberry|\n",
            "|0001|         Cake|0.55|donut|      5006|Chocolate with Sp...|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1004|       Devil's Food|\n",
            "|0001|         Cake|0.55|donut|      5003|           Chocolate|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0001|         Cake|0.55|donut|      5003|           Chocolate|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1002|          Chocolate|\n",
            "|0001|         Cake|0.55|donut|      5003|           Chocolate|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1003|          Blueberry|\n",
            "|0001|         Cake|0.55|donut|      5003|           Chocolate|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1004|       Devil's Food|\n",
            "|0001|         Cake|0.55|donut|      5004|               Maple|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0001|         Cake|0.55|donut|      5004|               Maple|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1002|          Chocolate|\n",
            "|0001|         Cake|0.55|donut|      5004|               Maple|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1003|          Blueberry|\n",
            "|0001|         Cake|0.55|donut|      5004|               Maple|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1004|       Devil's Food|\n",
            "|0002|       Raised|0.55|donut|      5001|                None|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0002|       Raised|0.55|donut|      5002|              Glazed|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0002|       Raised|0.55|donut|      5005|               Sugar|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0002|       Raised|0.55|donut|      5003|           Chocolate|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0002|       Raised|0.55|donut|      5004|               Maple|                NULL|    NULL|                NULL|                    NULL|                   NULL|               NULL|             1001|            Regular|\n",
            "|0003|Old Fashioned|0.55|donut|      5001|                None|\"m2yskBQFythfE4ir...|       1|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Film & Animation|             1001|            Regular|\n",
            "|0003|Old Fashioned|0.55|donut|      5001|                None|\"m2yskBQFythfE4ir...|       1|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Film & Animation|             1002|          Chocolate|\n",
            "|0003|Old Fashioned|0.55|donut|      5002|              Glazed|\"m2yskBQFythfE4ir...|       1|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Film & Animation|             1001|            Regular|\n",
            "|0003|Old Fashioned|0.55|donut|      5002|              Glazed|\"m2yskBQFythfE4ir...|       1|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Film & Animation|             1002|          Chocolate|\n",
            "|0003|Old Fashioned|0.55|donut|      5003|           Chocolate|\"m2yskBQFythfE4ir...|       1|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Film & Animation|             1001|            Regular|\n",
            "|0003|Old Fashioned|0.55|donut|      5003|           Chocolate|\"m2yskBQFythfE4ir...|       1|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Film & Animation|             1002|          Chocolate|\n",
            "|0003|Old Fashioned|0.55|donut|      5004|               Maple|\"m2yskBQFythfE4ir...|       1|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Film & Animation|             1001|            Regular|\n",
            "|0003|Old Fashioned|0.55|donut|      5004|               Maple|\"m2yskBQFythfE4ir...|       1|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Film & Animation|             1002|          Chocolate|\n",
            "|0003|Old Fashioned|0.55|donut|      5001|                None|\"m2yskBQFythfE4ir...|       2|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Autos & Vehicles|             1001|            Regular|\n",
            "|0003|Old Fashioned|0.55|donut|      5001|                None|\"m2yskBQFythfE4ir...|       2|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Autos & Vehicles|             1002|          Chocolate|\n",
            "|0003|Old Fashioned|0.55|donut|      5002|              Glazed|\"m2yskBQFythfE4ir...|       2|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Autos & Vehicles|             1001|            Regular|\n",
            "|0003|Old Fashioned|0.55|donut|      5002|              Glazed|\"m2yskBQFythfE4ir...|       2|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Autos & Vehicles|             1002|          Chocolate|\n",
            "|0003|Old Fashioned|0.55|donut|      5003|           Chocolate|\"m2yskBQFythfE4ir...|       2|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Autos & Vehicles|             1001|            Regular|\n",
            "|0003|Old Fashioned|0.55|donut|      5003|           Chocolate|\"m2yskBQFythfE4ir...|       2|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Autos & Vehicles|             1002|          Chocolate|\n",
            "|0003|Old Fashioned|0.55|donut|      5004|               Maple|\"m2yskBQFythfE4ir...|       2|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Autos & Vehicles|             1001|            Regular|\n",
            "|0003|Old Fashioned|0.55|donut|      5004|               Maple|\"m2yskBQFythfE4ir...|       2|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|   Autos & Vehicles|             1002|          Chocolate|\n",
            "|0003|Old Fashioned|0.55|donut|      5001|                None|\"m2yskBQFythfE4ir...|      10|youtube#videoCate...|                    true|   UCBR8-60-B28hp2Bm...|              Music|             1001|            Regular|\n",
            "+----+-------------+----+-----+----------+--------------------+--------------------+--------+--------------------+------------------------+-----------------------+-------------------+-----------------+-------------------+\n",
            "only showing top 50 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s16dTBzNOhg3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}